# [Code for ICLR 2025: TOWARDS OUT-OF-MODAL GENERALIZATION WITHOUT INSTANCE-LEVEL MODAL CORRESPONDENCE](https://openreview.net/pdf?id=LuVulfPgZN)

Zhuo Huang<sup>1</sup>, Gang Niu<sup>2</sup>, Bo Han<sup>3, 2</sup>, Masashi Sugiyama<sup>2, 4</sup>, Tongliang Liu<sup>1, 2</sup>

<sup>1</sup>USYD, <sup>2</sup>RIKEN, <sup>3</sup>HKBU, <sup>4</sup>UTokyo

The world is understood from various modalities, such as appearance, sound, language, etc. Since each modality only partially represents objects in a certain physical meaning, leveraging additional ones is beneficial in both theory and practice. However, exploiting novel modalities normally requires cross-modal pairs corresponding to the same instance, which is extremely resource-consuming and sometimes even impossible, making knowledge exploration of novel modalities largely restricted. To seek practical multi-modal learning, here we study Out-of-Modal (OOM) Generalization as an initial attempt to generalize to an unknown modality without given instance-level modal correspondence. Specifically, we consider Semi-Supervised and Unsupervised scenarios of OOM Generalization, where the first has scarce correspondences and the second has none, and propose connect & explore (COX) to solve these problems. COX first connects OOM data and known In-Modal (IM) data through a variational information bottleneck framework to extract shared information. Then, COX leverages the shared knowledge to create emergent correspondences, which is theoretically justified from an information-theoretic perspective. As a result, the label information on OOM data emerges along with the correspondences, which help explore the OOM data with unknown knowledge, thus benefiting generalization results. We carefully evaluate the proposed COX method under various OOM generalization scenarios, verifying its effectiveness and extensibility.
# 2025_ICLR_COX
